{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6dd379b",
   "metadata": {},
   "source": [
    "# <a name=\"0\">Machine Learning Accelerator - Natural Language Processing - Lecture 3</a>\n",
    "## Fine-tuning BERT for the Product Review Problem - Classify Product Reviews as Positive or Not\n",
    "\n",
    "Let's fine-tune the BERT model to classify our product reviews. We will install a new library __transformers__ and get a pre-trained BERT model from it. We are following [this tutorial](https://huggingface.co/transformers/custom_datasets.html) from the HuggingFace framework.\n",
    "\n",
    "We are using a light version of the original BERT implementation called __\"DistilBert\"__. You can checkout [their paper](https://arxiv.org/pdf/1910.01108.pdf) for more details. __This demo takes a long time to complete (even for 1 epoch) with our current instance. It is intended to get you familiar with this tool.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ba1165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r ../../requirements.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: torchtext==0.9.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r ../../requirements.txt (line 2)) (0.9.1)\n",
      "Requirement already satisfied: nltk==3.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r ../../requirements.txt (line 3)) (3.6.2)\n",
      "Requirement already satisfied: pandas==1.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r ../../requirements.txt (line 4)) (1.1.5)\n",
      "Requirement already satisfied: scikit-learn==0.24.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r ../../requirements.txt (line 5)) (0.24.1)\n",
      "Requirement already satisfied: numpy==1.19.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r ../../requirements.txt (line 6)) (1.19.5)\n",
      "Requirement already satisfied: trax==1.3.7 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r ../../requirements.txt (line 7)) (1.3.7)\n",
      "Requirement already satisfied: transformers==4.5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r ../../requirements.txt (line 8)) (4.5.1)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.8.1->-r ../../requirements.txt (line 1)) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.8.1->-r ../../requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.9.1->-r ../../requirements.txt (line 2)) (4.61.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.9.1->-r ../../requirements.txt (line 2)) (2.26.0)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nltk==3.6.2->-r ../../requirements.txt (line 3)) (2021.4.4)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nltk==3.6.2->-r ../../requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nltk==3.6.2->-r ../../requirements.txt (line 3)) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas==1.1.5->-r ../../requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas==1.1.5->-r ../../requirements.txt (line 4)) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn==0.24.1->-r ../../requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn==0.24.1->-r ../../requirements.txt (line 5)) (1.5.3)\n",
      "Requirement already satisfied: absl-py in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (1.15.0)\n",
      "Requirement already satisfied: jax in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (0.2.17)\n",
      "Requirement already satisfied: gym in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (0.21.0)\n",
      "Requirement already satisfied: tensorflow-text in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (2.6.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (4.4.0)\n",
      "Requirement already satisfied: funcsigs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (1.0.2)\n",
      "Requirement already satisfied: gin-config in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (0.5.0)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (5.8.0)\n",
      "Requirement already satisfied: jaxlib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (0.1.69)\n",
      "Requirement already satisfied: t5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from trax==1.3.7->-r ../../requirements.txt (line 7)) (0.9.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.5.1->-r ../../requirements.txt (line 8)) (4.8.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.5.1->-r ../../requirements.txt (line 8)) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.5.1->-r ../../requirements.txt (line 8)) (0.0.46)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.5.1->-r ../../requirements.txt (line 8)) (21.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.5.1->-r ../../requirements.txt (line 8)) (3.0.12)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gym->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->transformers==4.5.1->-r ../../requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: opt-einsum in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jax->trax==1.3.7->-r ../../requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jaxlib->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging->transformers==4.5.1->-r ../../requirements.txt (line 8)) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.9.1->-r ../../requirements.txt (line 2)) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.9.1->-r ../../requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.9.1->-r ../../requirements.txt (line 2)) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.9.1->-r ../../requirements.txt (line 2)) (2021.10.8)\n",
      "Requirement already satisfied: tfds-nightly in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (4.4.0.dev202112080110)\n",
      "Requirement already satisfied: seqio in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.0.7)\n",
      "Requirement already satisfied: sacrebleu in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (2.0.0)\n",
      "Requirement already satisfied: mesh-tensorflow[transformer]>=0.1.13 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.1.19)\n",
      "Requirement already satisfied: rouge-score in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.0.4)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.1.96)\n",
      "Requirement already satisfied: babel in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (2.9.1)\n",
      "Requirement already satisfied: editdistance in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.3.4)\n",
      "Requirement already satisfied: importlib-resources in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../../requirements.txt (line 7)) (5.4.0)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.18.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../../requirements.txt (line 7)) (21.2.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../../requirements.txt (line 7)) (3.19.0)\n",
      "Requirement already satisfied: promise in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../../requirements.txt (line 7)) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (2.6.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.42.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (2.6.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (2.6.0)\n",
      "Requirement already satisfied: clang~=5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (5.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.1.2)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacrebleu->t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.4.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacrebleu->t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.8.9)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacrebleu->t5->trax==1.3.7->-r ../../requirements.txt (line 7)) (2.3.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow-metadata->tensorflow-datasets->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.53.0)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.5.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (58.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.30.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow<2.7,>=2.6.0->tensorflow-text->trax==1.3.7->-r ../../requirements.txt (line 7)) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../../requirements.txt\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5704cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from transformers import Trainer, TrainingArguments, DistilBertForSequenceClassification, DistilBertTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb7d0ab",
   "metadata": {},
   "source": [
    "Let's read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ac0d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/examples/NLP-REVIEW-DATA-CLASSIFICATION-TRAINING.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb894dae",
   "metadata": {},
   "source": [
    "Let's print the dataset information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2933af02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56000 entries, 0 to 55999\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   ID          56000 non-null  int64  \n",
      " 1   reviewText  55990 non-null  object \n",
      " 2   summary     55988 non-null  object \n",
      " 3   verified    56000 non-null  bool   \n",
      " 4   time        56000 non-null  int64  \n",
      " 5   log_votes   56000 non-null  float64\n",
      " 6   isPositive  56000 non-null  float64\n",
      "dtypes: bool(1), float64(2), int64(2), object(2)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f011a97",
   "metadata": {},
   "source": [
    "We drop rows with text field missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2b5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"reviewText\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2575292",
   "metadata": {},
   "source": [
    "BERT requires powerful compute power. In this demo, we will only use the first 1,000 data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f210626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c3e78",
   "metadata": {},
   "source": [
    "We set the output type to int64 as it is required by this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c920977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isPositive\"] = df[\"isPositive\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4c4c4",
   "metadata": {},
   "source": [
    "Let's keep 10% of the data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8350a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This separates 10% of the entire dataset into validation dataset.\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"reviewText\"].tolist(),\n",
    "    df[\"isPositive\"].tolist(),\n",
    "    test_size=0.10,\n",
    "    shuffle=True,\n",
    "    random_state=324,\n",
    "    stratify = df[\"isPositive\"].tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a7292",
   "metadata": {},
   "source": [
    "Let's get the special tokenizer for BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aabaac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_texts,\n",
    "                            truncation=True,\n",
    "                            padding=True)\n",
    "val_encodings = tokenizer(val_texts,\n",
    "                          truncation=True,\n",
    "                          padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4bb8fd",
   "metadata": {},
   "source": [
    "We prepare our data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abd29be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "train_dataset = ReviewDataset(train_encodings, train_labels)\n",
    "val_dataset = ReviewDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686fa8cb",
   "metadata": {},
   "source": [
    "Let's call the model. This may print some warning messages. We are using it as intended, so don't worry about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7450ac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",\n",
    "                                                            num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c61b0e",
   "metadata": {},
   "source": [
    "Let's start the fine-tuning process. This code takes __a long time__ to complete. It is intended for educational purposes. It usually requires a bigger instance for a quicker run. You can reduce the __num_train_epochs__ in your run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32e128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='660' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 660/1140 2:04:53 < 1:31:06, 0.09 it/s, Epoch 11.56/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>0.662290</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>56.648700</td>\n",
       "      <td>1.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.643900</td>\n",
       "      <td>0.626768</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>55.992400</td>\n",
       "      <td>1.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.599400</td>\n",
       "      <td>0.576111</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>57.219400</td>\n",
       "      <td>1.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.532700</td>\n",
       "      <td>0.509893</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>57.388100</td>\n",
       "      <td>1.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.470800</td>\n",
       "      <td>0.451325</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>56.897100</td>\n",
       "      <td>1.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.416415</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>57.070000</td>\n",
       "      <td>1.752000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A simple function to calc. accuracy\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # calculate accuracy using sklearn's function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "      'accuracy': acc\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results\",  # output directory\n",
    "    num_train_epochs=20,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=\"logs\",  # directory for storing logs\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",  # print val score at each step\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# Freeze the encoder weights until the classfier\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  # the Transformers model\n",
    "    args=training_args,  # training arguments\n",
    "    train_dataset=train_dataset,  # passing training dataset\n",
    "    eval_dataset=val_dataset,  # passing evaluation dataset\n",
    "    compute_metrics=compute_metrics  # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da8c10d",
   "metadata": {},
   "source": [
    "Let's use the trained model to make predictions on the validation dataset and compute metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe4c29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = trainer.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a44b12",
   "metadata": {},
   "source": [
    "We get validation predictions using the argmax function. It returns 0 or 1 for each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0ec2ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  7]\n",
      " [ 7 54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        39\n",
      "           1       0.89      0.89      0.89        61\n",
      "\n",
      "    accuracy                           0.86       100\n",
      "   macro avg       0.85      0.85      0.85       100\n",
      "weighted avg       0.86      0.86      0.86       100\n",
      "\n",
      "Accuracy (validation): 0.86\n"
     ]
    }
   ],
   "source": [
    "preds = val_predictions.predictions.argmax(-1)\n",
    "\n",
    "print(confusion_matrix(val_predictions.label_ids, preds))\n",
    "print(classification_report(val_predictions.label_ids, preds))\n",
    "print(\"Accuracy (validation):\", accuracy_score(val_predictions.label_ids, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a467cef",
   "metadata": {},
   "source": [
    "### Looking at what's going on\n",
    "\n",
    "The fine-tuned BERT is able to correctly classify the sentiment of all records in the validation set. Let's print some of the data and what's happening with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a338402c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[101, 1045, 4149, 2023, 2138, 6881, 3769, 1011, 2039, 21628, 2015, 2020, 4760, 2039, 2006, 2026, 12191, 1012, 2023, 10770, 3036, 4031, 2134, 1005, 1056, 2131, 9436, 1997, 2068, 1010, 2061, 1045, 2001, 9364, 1010, 2021, 2009, 2052, 3796, 1996, 4180, 1012, 2061, 2009, 4066, 1997, 2499, 1010, 2021, 1045, 4299, 2009, 2071, 4550, 2039, 2026, 3274, 2062, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "I bought this because weird pop-up tabs were showing up on my laptop. This Norton security product didn't get rid of them, so I was disappointed, but it would block the content.  So it sort of worked, but I wish it could clean up my computer more.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "print(len(val_dataset.encodings[\"input_ids\"][k]))\n",
    "print(val_dataset.encodings[\"input_ids\"][k])\n",
    "print(val_texts[k])\n",
    "print(val_labels[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06888acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[101, 1045, 2031, 2109, 2119, 22432, 7959, 2063, 1998, 10770, 1998, 2044, 2383, 2109, 2023, 4007, 2005, 2058, 1037, 2095, 2085, 1045, 2079, 2025, 2933, 2000, 2689, 1012, 2009, 2515, 2025, 4030, 2091, 2026, 3274, 1012, 1045, 2224, 2009, 2006, 2026, 7473, 1998, 14960, 1012, 2009, 2038, 7420, 2033, 1997, 4022, 4795, 4773, 4573, 2008, 1996, 2060, 2048, 2106, 2025, 1998, 2009, 2003, 16286, 21125, 1012, 6581, 4007, 2005, 4274, 3036, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "I have used both McAfee and Norton and after having used this software for over a year now I do not plan to change. It does not slow down my computer. I use it on my PC and notebook. It has warned me of potential dangerous web sites that the other two did not and it is reasonably priced. Excellent software for internet security.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "k = 24\n",
    "print(len(val_dataset.encodings[\"input_ids\"][k]))\n",
    "print(val_dataset.encodings[\"input_ids\"][k])\n",
    "print(val_texts[k])\n",
    "print(val_labels[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e18c2",
   "metadata": {},
   "source": [
    "Let's observe in more detail how sentences are tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9537222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have used both McAfee and Norton and after having used this software for over a year now I do not plan to change. It does not slow down my computer. I use it on my PC and notebook. It has warned me of potential dangerous web sites that the other two did not and it is reasonably priced. Excellent software for internet security.\n",
      "{'input_ids': [101, 1045, 2031, 2109, 2119, 22432, 7959, 2063, 1998, 10770, 1998, 2044, 2383, 2109, 2023, 4007, 2005, 2058, 1037, 2095, 2085, 1045, 2079, 2025, 2933, 2000, 2689, 1012, 2009, 2515, 2025, 4030, 2091, 2026, 3274, 1012, 1045, 2224, 2009, 2006, 2026, 7473, 1998, 14960, 1012, 2009, 2038, 7420, 2033, 1997, 4022, 4795, 4773, 4573, 2008, 1996, 2060, 2048, 2106, 2025, 1998, 2009, 2003, 16286, 21125, 1012, 6581, 4007, 2005, 4274, 3036, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "st = val_texts[24]\n",
    "print(st)\n",
    "tok = tokenizer(st, truncation=True, padding=True)\n",
    "print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "787f1d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mapped vocabulary is stored in tokenizer.vocab\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d529fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', 'have', 'used', 'both', 'mca', '##fe', '##e', 'and', 'norton', 'and', 'after', 'having', 'used', 'this', 'software', 'for', 'over', 'a', 'year', 'now', 'i', 'do', 'not', 'plan', 'to', 'change', '.', 'it', 'does', 'not', 'slow', 'down', 'my', 'computer', '.', 'i', 'use', 'it', 'on', 'my', 'pc', 'and', 'notebook', '.', 'it', 'has', 'warned', 'me', 'of', 'potential', 'dangerous', 'web', 'sites', 'that', 'the', 'other', 'two', 'did', 'not', 'and', 'it', 'is', 'reasonably', 'priced', '.', 'excellent', 'software', 'for', 'internet', 'security', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Methods convert_ids_to_tokens and convert_tokens_to_ids allow to see how sentences are tokenized\n",
    "print(tokenizer.convert_ids_to_tokens(tok['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557dc49d",
   "metadata": {},
   "source": [
    "# Getting predictions on the test data and saving results\n",
    "* Read the test data\n",
    "* Pass the data into your pipeline and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea436643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>time</th>\n",
       "      <th>log_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33276</td>\n",
       "      <td>I've been using greeting card software for wel...</td>\n",
       "      <td>Absolutely awful.</td>\n",
       "      <td>False</td>\n",
       "      <td>1300233600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20859</td>\n",
       "      <td>This version worked well for me, have upgraded...</td>\n",
       "      <td>Good for virtual machine on a mac</td>\n",
       "      <td>True</td>\n",
       "      <td>1448755200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63500</td>\n",
       "      <td>Great!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>True</td>\n",
       "      <td>1456963200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4950</td>\n",
       "      <td>I can assure you that any five star review was...</td>\n",
       "      <td>SCAM</td>\n",
       "      <td>False</td>\n",
       "      <td>1400803200</td>\n",
       "      <td>2.197225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26509</td>\n",
       "      <td>Overall the product really seems the same but ...</td>\n",
       "      <td>Has potential but many glitches and really the...</td>\n",
       "      <td>False</td>\n",
       "      <td>1419206400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                         reviewText  \\\n",
       "0  33276  I've been using greeting card software for wel...   \n",
       "1  20859  This version worked well for me, have upgraded...   \n",
       "2  63500                                             Great!   \n",
       "3   4950  I can assure you that any five star review was...   \n",
       "4  26509  Overall the product really seems the same but ...   \n",
       "\n",
       "                                             summary  verified        time  \\\n",
       "0                                  Absolutely awful.     False  1300233600   \n",
       "1                  Good for virtual machine on a mac      True  1448755200   \n",
       "2                                         Five Stars      True  1456963200   \n",
       "3                                               SCAM     False  1400803200   \n",
       "4  Has potential but many glitches and really the...     False  1419206400   \n",
       "\n",
       "   log_votes  \n",
       "0   0.000000  \n",
       "1   0.000000  \n",
       "2   0.000000  \n",
       "3   2.197225  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test data (It doesn't have the human_tag label, we are trying to predict that :D )\n",
    "df_test = pd.read_csv(\"../../data/examples/NLP-REVIEW-DATA-CLASSIFICATION-TEST.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81a78039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID            0\n",
       "reviewText    1\n",
       "summary       2\n",
       "verified      0\n",
       "time          0\n",
       "log_votes     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf14b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"reviewText\"] = df_test[\"reviewText\"].fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e934007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = df_test[\"reviewText\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45ca9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(test_texts,\n",
    "                          truncation=True,\n",
    "                          padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8af3a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ReviewDataset(test_encodings, [0]*len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafff183",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_predictions.predictions.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbcbaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "print(len(test_dataset.encodings[\"input_ids\"][k]))\n",
    "print(test_dataset.encodings[\"input_ids\"][k])\n",
    "print(test_texts[k])\n",
    "#check whether the prediction is good enough\n",
    "print(test_preds[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "result_df[\"ID\"] = df_test[\"ID\"]\n",
    "result_df[\"isPositive\"] = test_preds\n",
    "\n",
    "result_df.to_csv(\"result_day3_bert.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76377134",
   "metadata": {},
   "source": [
    "This command deletes saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc49cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6253b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa35c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
